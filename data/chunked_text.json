{
  "1": [
    "Eur. Phys. J. Spec. Top. (2024) 233:225–240\nhttps://doi.org/10.1140/epjs/s11734-023-01010-4\nTHE EUROPEAN\nPHYSICAL JOURNAL\nSPECIAL TOPICS\nReview\nStatus and prospects of the LHCb experiment\nPatrick Owen and Nicola Serraa\nPhysik-Institut, Universit¨at Z¨urich, 8057 Z¨urich, Switzerland\nReceived 22 September 2023 / Accepted 7 November 2023 / Published online 2 January 2024\n © The Author(s) 2023\n",
    "Abstract We discuss the status and prospects of the Large Hadron Collider beauty (LHCb) experiment,\none of the four large detectors based at the LHC. The physics programme of the experiment is discussed\nby highlighting the status of rare b-quark decays, charged current semileptonic decays and the searches for\nCP violation.",
    "These areas make a strong cases for a second upgrade of LHCb, which will fully harness the\nHL-LHC’s potential as a ﬂavour physics machine while maintaining a rich and diverse research programme.\n The upgrade also provides an opportunity for the development of novel detector technologies during an\nexciting period of anticipation in preparation for the future circular collider currently foreseen.\n",
    "1 Introduction\nAt this unique juncture in particle physics, a multitude of theories once believed to be ideal complements to the\nStandard Model (SM) have been either disqualiﬁed or so signiﬁcantly conﬁned in their scope that they no longer\nhold the same prominence. However, the unresolved issues of the SM that were prevalent prior to the initiation of\nthe Large Hadron Collider (LHC) remain unresolved. These circumstances have led some to consider this to be a\nperiod of stagnation.",
    "Historically, such periods have often served as precursors to signiﬁcant breakthroughs. The\nchallenge we face is due to our inability to predict if this impending revolution will occur in the coming decade or\nnecessitate a more extended timeline. The initial two runs of the LHC have largely corroborated the SM, exceeding\nour own expectations.",
    "In this scenario, where there is no decisive conception of the scale and structure of New\nPhysics (NP), indirect searches and precision measurements emerge as highly promising avenues. Among these,\nprecise assessments of Flavour Physics hold particular intrigue as they could potentially elucidate the Flavour\npuzzle - the distinctive pattern of masses and couplings across diﬀerent families that, although described, remain\ninexplicable within the SM.",
    "In more technical terms, the intriguing aspect is that the gauge portion of the SM\nLangrangian has an extensive discrete symmetry, U(3)5, which is broken by the Higgs mechanism via Yukawa\ncouplings and is suggestive of a concealed dynamics at work.\n Among the various ﬂavour-physics experiments, LHCb has been one of the most prominent for the last 15 years.\n",
    "The reason for this is due to the unique sensitivity, meaning that LHCb results from both the original detector\nand its upgrades have the potential to signiﬁcantly inﬂuence the future direction of particle physics. The LHCb\nexperiment [1] is one of the four large detectors located at the LHC and is speciﬁcally designed to study the decays\nof beauty and charm quarks.",
    "Unlike the ATLAS and CMS detectors, LHCb is designed more like a ﬁxed target\nexperiment, with the collision point situated on one side of the detector. This single-arm forward spectrometer\ngeometry allows the maximum amount of space in which to instrument in a single direction, which is crucial to\nthe performance of particle ID and momentum resolution. This is at the expense of having a smaller acceptance,\nwhere only the pseudo-rapidity range 2 < η < 5.0 is instrumented.",
    "However, due to the particular nature of b¯b\nproduction at the LHC, most beauty quarks are produced in the forward direction, and therefore around 20% of\nwhich decay within the LHCb acceptance.\n Being situated at the LHC, the LHCb detector operates in a hadronic environment, with hundreds of particles\nproduced in every hard pp interaction. This is in contrast to the B-factories, where two B-mesons are much more\nisolated and kinematically constrained.",
    "The reason why LHCb can compete in this environment is due to the huge\nproduction rate at the LHC. For example, starting from 2035, the high-luminosity LHC will produce O(100 M)\nbeauty quark pairs every second [2]. This is equivalent to producing a B-factory dataset every 10 s, albiet in much\na e-mail: nicola.serra@cern.ch (corresponding author)\n123\n"
  ],
  "2": [
    "226\nEur. Phys. J. Spec. Top. (2024) 233:225–240\nharsher conditions. The exploitation of this huge dataset for the purposes of heavy ﬂavour physics is a formidable,\nyet as we will discuss later, rewarding challenge.\n 2 Status of the LHCb experiment\nAside from its geometry, the LHCb detector has a few features which distinguish it when compared to\nthe other experiments at the LHC.",
    "Firstly, the vertex detector (VELO) is placed only 5.1 mm from the\nbeam, allowing for an excellent impact parameter resolution of roughly 35 μm depending on the transverse\nmomentum of the particle. This is vitally important for timing resolution and to reject particles that orig-\ninate from the primary pp collision. Another feature of LHCb crucially important for heavy ﬂavour physics\nis the ability to identify hadrons.",
    "This is provided by ring imaging Cherenkov detectors (RICH), situated\nupstream and downstream of a dipole magnet. The tracking system, comprised of the VELO, a silicon track-\ning system situated upstream of the magnet and further tracking stations downstream. These provide an\nexcellent momentum resolution resulting in ∼20 MeV mass resolution for a fully reconstructed b-hadron\ndecay.\n The LHCb experiment does not operate at the maximum luminosity of 2×1034 cm−2 s−1 currently accesable at\nthe LHC.",
    "The reason for this choice is ﬁrstly due to the very large occupancies in the forward region of the LHC,\nwhich would make particle reconstruction prohibitively complicated. The second reason is due to the extremely\nhigh signal rates, resulting in unfeasible requirements for any trigger or DAQ system realisable with current\ntechnology. The luminosity is therefore ‘levelled’ by defocusing the beam at the interaction point, allowing for a\nmore manageable data rate and simpler to analyse.",
    "During runs I and II, the luminosity at LHCb was levelled to a\nmaximum rate of 4 × 1032 cm−2 s1, which resulted in around 1–2 hard pp interactions per bunch crossing. In this\nenvironment the ﬁrst level of the trigger system, based on partial readout such as high transerve energy clusters\nin the calorimeters, was able to achieve good eﬃciency for a wide variety of signatures.\n",
    "For the ongoing LHC run III, the luminosity will be levelled to a rate of 2 × 1033 cm−2 s−1, a ﬁve-fold increase\nfrom the previous runs. At this luminosity, there are around 7 pp interactions per bunch crossing, which is\na signiﬁcantly more challenging environment for both triggering and reconstruction.",
    "The LHCb detector was\ntherefore upgraded [3] to meet this challenge: The tracking systems were replaced, with the strips in the VELO\nreplaced by a pixel detector; the Tracker Turicensis was replaced by the Upstream Tracker improving to material\nbudget and increased acceptance and ﬁnally the Outer and Inner Trackers were replaced with Scintilating Fibres.\n These upgrades improved the occupancy and radiation hardness, which are mandatory upgrades to deal with the\nincreased data.\n",
    "The second important aspect of the LHCb upgrade 1 is the near-complete replacement of the readout electron-\nics, allowing for the full detector to be readout at the bunch crossing rate of 30MHz. This allows for a trigger\nsystem that is fully implemented in software. The main advantage of this is to utilise the large impact parameter\nof particles that originate from beauty and charm hadron decays.",
    "This allows to have softer transverse momen-\ntum requirements compared to the original trigger system, which substantially improves the eﬃciency for fully\nhadronic decays which, among other things, are of crucial importance for LHCb’s CP-violation programme dis-\ncussed later on in this review. The LHCb upgrade 1 has now been completed, and the detector is currently being\ncommissioned.",
    "A total of 50 fb−1 are expected to be taken during the next two run periods until 2032, which will\nallow for signiﬁcantly more precise measurements in addition to a broader programme enabled by the new trigger\nsystem.\n The LHCb physics programme includes a large and diverse set of measurements, including studies of charm\ndecays, electroweak physics and analyses of heavy-ion collisions.",
    "In this review, we focus on measurements per-\nformed with b-hadron decays, which remain a core part of the experiment’s physics potential. The b physics\nprogramme is summarised by highlighting three areas: Studies of rare b decays, measurements of charged-current\nsemileptonic decays and searches for new sources of CP violation.\n",
    "3 Rare decays\nRare decays of b-hadrons serve as promising probes for NP, as they are suppressed and can therefore introduce\ncontributions from NP that are competitive with the SM decay amplitude. A particularly sensitive set of rare\ndecays are those proceeding via ﬂavour-changing-neutral-currents (FCNC), where a b-quark transitions into either\na strange or down quark.",
    "FCNCs have had a signiﬁcant historical impact in the construction of the SM, for example\nwhich led Glashow, Iliopoulos, and Maiani to predict the existence of the charm quark (c) [4]. Interestingly, when\noperators of dimensions greater than four are added to the Standard Model (SM), FCNC transitions naturally\nemerge, a key reason why rare decays are often targeted in the search for NP. Rare decays play an outsized role in\n123\n"
  ],
  "3": [
    "Eur. Phys. J. Spec. Top. (2024) 233:225–240\n227\nthe physics programme of LHCb as the experiment has a unique sensitivity, thanks to the vast number of b-quarks\nproduced at the LHC and its exceptional performance in particle identiﬁcation, momentum, and vertex resolution\nwhich is crucial for background control.\n",
    "In a scenario where we postulate that there are no new particles below the electroweak scale, we can characterise\nb →sℓ+ℓ−transitions using an eﬀective Lagrangian encompassing only light SM ﬁelds. The main distinction\nbetween the SM and eﬀective Lagrangians, renormalized at a scale μ ∼mb, is the number of eﬀective operators,\nwhich can be more extensive in the NP case, in addition to the value of the corresponding coeﬃcients.\n",
    "ΔLb→sℓℓ\nNP\n= 4GF\n√\n2\n\u0002\ni\nCiOi + h.c.,\n(1)\nwhere GF denotes the Fermi constant, and where the index i indicates the following set of dimension-six operators\n(treated independently for ℓ= e and μ):\nOℓ\n9 = (¯sLγμbL)(¯ℓγμℓ),\nOℓ\n10 = (¯sLγμbL)(¯ℓγμγ5ℓ) ,\nOℓ′\n9 = (¯sRγμbR)(¯ℓγμℓ),\nOℓ′\n10 = (¯sRγμbR)(¯ℓγμγ5ℓ) ,\nOℓ\nˆS = (¯sLbR)(¯ℓRℓL),\nOℓ′\nˆS = (¯sRbL)(¯ℓLℓR) .\n",
    "(2)\nThis methodological approach is highly eﬀective in correlating diﬀerent decays, not only facilitating a combined\ninterpretation of diﬀerent measurements for enhanced sensitivity but also leveraging the coherence of various modes\nto mitigate the impact of statistical and systematic eﬀects.\n In recent years, several discrepancies in rare decays have emerged, which form a large part of the so-called ﬂavour\nanomalies.",
    "The anomalies related to rare decays comprised of three types of measurements: lower than predicted\nbranching fractions for various b →sμμ decays [5–7], a deviation in the angular distrubution of B →K∗μ+μ−\ndecays [8, 9], and previous deviations in tests of lepton ﬂavour universality. Furthermore, discrepancies with respect\nto the SM in tree-level semiltauonic decays, proceeding through b →cτν processes, have been identiﬁed and will\nbe elaborated upon in the next section.\n",
    "The ﬁrst anomaly in rare decays observed was a discrepancy in the angular distribution of the decay B →\nK∗μ+μ−[10], speciﬁcally in the observable P ′\n5 [11, 12], which was later corroborated by further measurements [8,\n9]. An eﬀective ﬁeld theory analysis of the deviation points towards a lower than expected value of the Wilson\ncoeﬃcient, C9, which is the coupling associated with the vector current to the di-lepton pair at the level of around\n3σ standard deviations.",
    "One of the striking features of this interpretation is that such a shift is numerically\nconsistent with the lower branching fractions seen in other decay modes, which dampens the possibility of a\nstatistical ﬂuctation. Despite this intriguing coherence, it appears that a theoretical breakthrough is necessary\nfor deﬁnitive conclusions, as they indicate a shift to C9 which can also be aﬀected by long-distance contributions\nfrom decays b →s¯cc, where the c¯c annihilates to form the two leptons.",
    "As c¯c decay proceeds via a photon, the\ncontribution interferes with the vector contribution of pure semileptonic b →sμμ decay and can mimic a NP eﬀect.\n As this c¯c contribution is fully hadronic, it is very diﬃcult to compute and is therefore controlling it is the main\navenues to clarify the situation. Approaches using data [13–17] have been proposed and implemented in order to\nhelp constrain the theoretical predictions.",
    "At the current moment there is not yet a consensus on the size of this\neﬀect, but progress is being steadily made (see for example Ref. [18]).\n Fortunately, this issue is not present for fully leptonic rare decays, of the type B(s) →ℓ+ℓ−, as they can\nproceed only in the SM with an axial-vector coupling to the two leptons.",
    "A famous example of this type is the\ndecay Bs →μ+μ−, which has long been considered a critical channel for the search for NP due to its helicity\nsuppression as well as that from the GIM mechanism. This makes it signiﬁcantly enhanced in models with an\nextended Higgs sector, such as the MSSM, where the branching ratio is proportional to tan6 β [19–22].",
    "In terms of\neﬀective operators, NP can contribute new scalar/pseudoscalar operators, yielding non-zero values for the Wilson\ncoeﬃcients C(′)\nS, P or by modifying the value of the axial-vector coeﬃcient C10. The main challenge in the experiment\nfor this decay is to distinguish it from background sources which have much larger branching fractions compared\nto the ultra rare decay rate.\n The latest LHCb measurement has measured the value of B(Bs →μμ) = 3.09+0.48\n−0.44 × 10−9",
    "[23], the value of\nwhich is consistent with the SM prediction [24, 25]. More recently, the CMS experiment updated their result to\nB(Bs →μμ) = (3.66±0.14)×10−9 [26]. A combination of various measurements of these branching ratios including\none from ATLAS [27] limits potential NP contributions to C10.\n",
    "In the absence of substantial theoretical advancement for rare semileptonic decays, one viable approach to\naddress the anomalies observed in b →sμ+μ−processes, assuming they are a result of NP, would be to relate\nthem to other phenomena and look for predicted signatures in those systems. Consequently, when tests on lepton\nuniversality in b →sℓ+ℓ−processes at LHCb displayed discrepancies with respect to the Standard Model (SM),\n123\n"
  ],
  "4": [
    "228\nEur. Phys. J. Spec. Top. (2024) 233:225–240\n it was reasonable to consider these discrepancies as potentially related (see Refs. [28, 29] and references therein).\n The following ratio of branching ratios, denoted by R(Xs, q2\nmin, q2\nma), are considered:\nR(Xs, q2\nmin, q2\nmax) =\n\u0003 q2\nmax\nq2\nmin\ndB(Xsμ+μ−)\ndq2\n\u0003 q2max\nq2\nmin\ndB(Xse+e−)\ndq2\n.\n (3)\nLepton Universality is an accidental symmetry of the SM. Hence, it would not be surprising for extensions of the\nSM to break it.",
    "Although the quantity in Eq. (3) is theoretically clean (see Refs. [30, 31] for discussions on theory\nuncertainty), its experimental measurement is more challenging, particularly at LHCb.\n These experimental challenges arise from the signiﬁcantly larger bremsstrahlung radiation of electrons compared\nto muons, which results in poorer momentum resolution. This, in turn, leads to lower eﬃciency, poorer invariant\nmass resolution, and ultimately, more complex handling of various backgrounds.\n",
    "LHCb had initially measured the observables RK [32], RK∗[33], RKS [34] and RpK [35] to be all below unity,\nwith a local combined signiﬁcance [36] exceeding four standard deviations. This brought considerable attention to\nthe ﬂavour anomalies, as they appeared to present a coherent pattern involving a non-lepton universal NP coupling\nCV = C9 −C10.\n The general analysis strategy comprises the following steps.",
    "The primary trigger for electron events utilizes the\nelectromagnetic calorimeter, a method that is less eﬃcient than triggering muons, which is accomplished through\nthe muon detector. The remainder of the event is also utilized as an additional trigger line. To alleviate the issue\nof poor resolution caused by bremsstrahlung radiation, a bremsstrahlung recovery algorithm is implemented for\nthe electrons.",
    "This involves adding to the electron momentum the momentum of bremsstrahlung photons that are\ncompatible with the electron’s trajectory.\n The primary diﬀerence between the latest LHCb analysis [37, 38] and previous ones lies in the treatment of\nmisidentiﬁed B →hhhX type backgrounds that contaminate the electron channel. To account for all poten-\ntial hadron misidentiﬁed backgrounds, a data-driven procedure was developed.",
    "This involves creating a hadron\nbackground-enriched sample by inverting the PID criteria. The candidates are weighted according to their misiden-\ntiﬁcation probability, obtained with control channels. After subtracting the residual electron component, a high-\npurity background sample for single and double hadron misidentiﬁcation is obtained. This provides a template for\nﬁtting the invariant mass distributions, as shown in Fig. 1.\n5000\n5500\n6000\nm(K+e+e−)",
    "[MeV/c2]\n0\n50\n100\n150\n200\nCounts / (32 MeV/c2)\nLHCb\n9 fb−1\nRK central-q2\nData\nTotal\nSignal\nCombinatorial\nMisidentiﬁcation\nPartially reconstructed\nB+ →K+J/ψ(→e+e−)\n5000\n5500\n6000\nm(K+π−e+e−) [MeV/c2]\n0\n20\n40\n60\n80\nCounts / (32 MeV/c2)\nLHCb\n9 fb−1\nRK∗central-q2\nData\nTotal\nSignal\nCombinatorial\nMisidentiﬁcation\nPartially reconstructed\nB0 →K∗0J/ψ(→e+e−)\n5000\n5500\n6000\nm(K+e+e−)",
    "[MeV/c2]\n0\n20\n40\n60\nCounts / (32 MeV/c2)\nLHCb\n9 fb−1\nRK low-q2\nData\nTotal\nSignal\nCombinatorial\nMisidentiﬁcation\nPartially reconstructed\nB+ →K+η (→e+e−γ)\n5000\n5500\n6000\nm(K+π−e+e−) [MeV/c2]\n0\n20\n40\n60\nCounts / (32 MeV/c2)\nLHCb\n9 fb−1\nRK∗low-q2\nData\nTotal\nSignal\nCombinatorial\nMisidentiﬁcation\nPartially reconstructed\nFig. 1 Invariant mass distribution of B+ →K+ℓ+ℓ−and B0 →K∗0ℓ+ℓ−for the muon mode (top four ﬁgures) and\nelectron mode (bottom four ﬁgures) with the ﬁt to data overimposed.",
    "Reproduced from Ref. [37]\n123\n"
  ],
  "5": [
    "Eur. Phys. J. Spec. Top. (2024) 233:225–240\n229\nFig. 2 Summary of the measurements for RK and RK∗across diﬀerent q2 regions, as reported by LHCb. Previous measure-\nments refer to [32, 33]. The more recent measurements [37, 38] have introduced improved background handling techniques\nand thus supersede the previous ones.",
    "Please note that the measurements of RK∗in the low-q2 region, as speciﬁed in\nthe cited references, were carried out within two distinct q2 ranges: 0.045 < q2 < 1.1 GeV2 and 0.01 < q2 < 1.1 GeV2,\nrespectively\nThe latest LHCb measurements of RK and RK∗perform the analysis in two diﬀerent regions of q2, resulting in\nfour diﬀerent measurements. These measurements are compatible with SM predictions, signiﬁcantly altering the\nbroader picture.",
    "Figure 2 compares the results previous analyses [33, 34] with the latest results [37, 38]in the four\nbins of q2.1 It’s worth emphasising that while these measurements align with the SM, they can still accommodate\na 5-10% lepton universality (LU) violation. The new results have strongly inﬂuenced global ﬁts for the ﬂavour\nanomalies, which were approaching a signiﬁcance of ﬁve standard deviations prior to these analyses (see e.g.\nRef. [39]).",
    "While diﬀerent groups yield compatible values under the same assumptions, papers obtaining diﬀerent\nsigniﬁcance values mainly diﬀer in how they handle non-local contributions from charm. Given the updated results\nand the current uncertainty of the c¯c contribution, the situation for the rare decays anomalies remains unresolved.\n Importantly, the uncertainty of the measurements is statistical, thus the LHCb Upgrade(s) will remain the\nprimary experiment for LU tests in rare decays.",
    "This is signiﬁcant because any LU violation would be a clear\nindication of NP. The anomalies have inspired innovative theoretical models that provide an intriguing explanation\nfor the ﬂavour puzzle. Many of these compelling models regard the third family as unique. For these models, LFU\ntests with the tau in the ﬁnal states are critical, while electron/muon LU violation can be minimal without causing\nissues for the models.",
    "Consequently, a promising way to test these models, besides semi-tauonic measurements,\nwould be rare decays with taus in the ﬁnal state of the type b →sττ.\n Most models that account for the ﬂavour anomalies through the addition of NP also predict potentially signiﬁcant\neﬀects in b →sττ transitions due to a hierarchical coupling to the diﬀerent generations. The current best limits\nare as follows:\nB(B0\ns →ττ) < 2.1 × 10−3 (95% CL)\nB(B+ →K+ττ)",
    "< 2.25 × 10−3 (90% CL)\nB(B0 →K∗0ττ) < 3.1 × 10−3 (90% CL).\n These were established by the LHCb [40], BaBar [41] and Belle [42] experiments. Evidently, rare decays involving\ntau particles in the ﬁnal state pose greater challenges than their counterparts involving electrons and muons, as\ntau particles decay before reaching the detector. The upgrade of the Belle experiment, Belle II, is expected to\nachieve a limit of 5.4 × 10−4 for B0 →K∗0ττ with a luminosity of 50 ab−1 [43].\n",
    "Such decays prove even more experimentally challenging at the LHCb experiment, where there is a high density\nof particles and the momentum of the decaying B-meson is unknown, in contrast to the Belle II experiment.\n 1Notice the diﬀerent q2-range for the low q2 bin in the latest LHCb analysis [37, 38] of RK, K∗and the previous analysis\nof RK∗[33].\n 123\n"
  ],
  "6": [
    "230\nEur. Phys. J. Spec. Top. (2024) 233:225–240\nTable 1 Table of decay modes, analysed data, and limits at 90% CL for various lepton ﬂavour violating modes\n Decay mode\nData analysed\nLimit at 90% CL\nB0 →K∗0μ±e∓\n9 fb−1\n9.9 × 10−9\nBs →φμ±e∓\n9 fb−1\n15.9 × 10−9\nB+ →K+μ−e+\n3 fb−1\n7.0 × 10−9\nB+ →K+μ+e−\n3 fb−1\n6.4 × 10−9\nB+ →K+μ−τ +\n9 fb−1\n3.9 × 10−5\nBs →μ±τ ∓\n3 fb−1\n3.9 × 10−5\nB0",
    "→μ±τ ∓\n3 fb−1\n1.2 × 10−5\nBs →μ±e∓\n3 fb−1\n5.4 × 10−9\nB0 →μ±e∓\n3 fb−1\n1.0 × 10−9\nτ →3μ\n3 fb−1\n4.6 × 10−8\nRegardless, LHCb established the world’s ﬁrst limit on Bs →ττ and (assuming no contribution of Bs), the best\nlimit on B0 →ττ [40]. Studies on B →Xsττ at LHCb are ongoing.\n Moreover, a signiﬁcant b →sττ NP contribution could be investigated in the dimuon spectrum of B+ →K+μμ\nby ﬁtting the dimuon spectrum, as suggested in Ref. [44].",
    "While this technique necessitates assumptions on the\ntheoretical model of the dimuon spectrum, it has the potential to yield results competitive with direct searches.\n Thus, such indirect searches could hold particular relevance for the LHCb upgrade II.\n Finally, the search for lepton ﬂavour violation (LFV) represents a fascinating area of study, as this accidental\nsymmetry is already violated in the Standard Model (SM) due to neutrino oscillations.",
    "However, the LFV induced\nby the SM is at an unmeasurably low level. Many extensions of the SM, including models aimed at explaining\nﬂavour anomalies, predict LFV at a level that upcoming particle physics experiments may be capable of measuring.\n Searches for LFV in the LHCb Upgrades complement those of dedicated experiments.",
    "Though it’s inherently more\nchallenging to determine LFV limits for the third family of quarks and leptons compared to the second family, the\npotential preferential coupling of NP to the third family might oﬀset these experimental constraints. A summary\nof LFV limits set by the LHCb experiment can be found in Table 1.\n Limits on τ →3μ are currently dominated by the Belle experiment, with Belle II anticipated to reach levels\nof a few parts in 10−10 assuming no background [43].",
    "For LHCb, surpassing the limits set by Belle II will pose a\nconsiderable challenge. However, sensitivity studies indicate that LHCb Upgrade II could also explore the level of\n10−9. It’s worth mentioning that LHCb might be the only experiment capable of potentially conﬁrming a discovery\nby Belle II.\n LHCb is leading in setting limits on b →sμe across all channels, as well as on b →sτμ. All these limits are\nstatistically limited and are expected to remain so after Run 3 and Run 4.",
    "It’s important to note that LHCb has\nbegun to explore an intriguing region for b →sτμ, making future measurements especially interesting.\n 4 Tree-level semileptonic decays\n In the SM, tree-level semileptonic decays of the type b →c, uℓ−¯νℓproceed via a charged-current interaction\nmediatated by the W boson.",
    "The presence of the weakly interacting neutrino in the ﬁnal state is an unambigu-\nous signal of a short-distance interaction, substantially simplifying the theoretical treatment as no long-distance\ncontributions are present. The price to pay for this theoretical clarity is large, however, as the signal is necessarily\npartially reconstructed. Therefore, it was a surprise that LHCb contributed as signiﬁcantly as it has in this system.\n",
    "Given their theoretical appeal, tree-level semileptonic decays are the ideal system to measure the magnitudes\nof the CKM elements Vub and Vcb. There are two main ways to determine these parameters. The ﬁrst is to study\ninclusive b →c(u)ℓνℓdecays, where all hadronic ﬁnal states of the charm or the up quark are included in the\nsignal. The second is to reconstruct an exclusive hadronic ﬁnal state such as B →πℓν.",
    "Measurements based on\nexclusive and inclusive methods have had a long-standing disagreement for more than a decade for both |Vub| and\n|Vcb| [45]. This disagreement is one of the issues that should be resolved to maximise the sensitivity for the test of\nCKM unitarity.\n Determining a CKM magnitude requires control over the absolute normalisation of the production and eﬃciency,\nwhich is diﬃcult at a hadron collider.",
    "Therefore, the strategy at LHCb is to normalise the b →u transition by a\ncorresponding b →c transition, thus performing a measurement of |Vub|/|Vcb|. This has been done with Λ0\nb →pμν\nand B0\ns →K+μ−ν decays, which are easier signatures than the canonical B →πμν decay used at the B-factories\n123\n"
  ],
  "7": [
    "Eur. Phys. J. Spec. Top. (2024) 233:225–240\n231\nAverage\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n0.55\nR(D)\n0.2\n0.25\n0.3\n0.35\n0.4\nR(D*)\nHFLAV SM Prediction\n 0.004\n±\nR(D) = 0.298 \n 0.005\n±\nR(D*) = 0.254 \n = 1.0 contours\n2\nχ\nΔ\nWorld Average\ntotal\n 0.029\n±\nR(D) = 0.357 \ntotal\n 0.012\n±\nR(D*) = 0.284 \n = -0.37\nρ\n) = 33%\n2\nχ\nP(\nσ\n3\na\nLHCb\nb\nLHCb\nb\nBelle\nc\nBelle\na\nBelle\nBaBar\nBelleII\nHFLAV\nSummer 2023\nFig. 3 Measurements and SM predictions (black) of the lepton universality ratios R(D) and R(D∗)",
    "[45]\ndue to the large amount of pions that originate from background sources. The main strategy of the analysis is to\ntake advantage of the high signal yields at LHCb to apply very tight selection criteria which improves the purity\nand consequently reduces systematic uncertainties associated with the background. An example of this is to select\ncandidates which have the best vertex resolution, as are more easily distinguished from background as well as\nhaving better kinematic resolution.\n",
    "When using lattice QCD, the results from LHCb agree with the B-factory results based on B →πμν. This\nagreement signiﬁcantly strengthens the conﬁdence in the exclusive determinations of |Vub| which will be crucial to\nﬁnally solving the inclusive-exclusive puzzle. The uncertainties are also competitive with those from the B-factories\nand are expected to reach an ultimate precision of 1% after the second LHCb upgrade [46], which relies on further\nprogress on lattice QCD techniques.\n",
    "On the |Vcb| side, the determination is strongly aﬀected by the treatment of the hadronic form factors and\nhow they are combined with the experimental data [47–50]. The diﬀerential shape of the branching fraction as a\nfunction of the decay kinematics such as the squared di-lepton mass q2 provides a large amount of experimental\ninformation in which to constrain the theory parameters.",
    "Here is where LHCb could provide a complementary\nmeasurement, as the large signal yields will result in very precise measurements in wider kinematic bins due to the\nlower resolution compared to the B-factories. These measurements will have a signiﬁcant impact, provided that\nsystematic uncertainties remain below the very high statistical precision.\n Due to their large branching fractions, semileptonic decays are a unique place to study decays involving the\nnotoriously diﬃcult τ-lepton.",
    "Despite its large SM amplitude, the decay b →cτ −¯ντ is highly sensitive to NP due\nto the large number of third-generation fermions involved in the decay. The branching fractions of these decays\nare tested with respect to the SM by normalising them to their muonic2 counterparts to form lepton universality\nratios\nR(Xc) = B(Xb →Xcτ −¯ντ)\nB(Xb →Xcμ−¯νμ)\n(4)\nwhich are predicted to be around 30% in the SM due to the kinematic suppression with the presence of the τ-\nlepton.",
    "τ-leptons are notoriously diﬃcult to reconstruct as they decay with at least one neutrino with a low visible\nbranching fraction. For semitauonic decays, this means at least two neutrinos missing from the decay, resulting in\na broad signal shape that is highly susceptable to backgrounds.\n There are two decay modes of the τ-lepton that are considered. The ﬁrst is the leptonic decay τ −→μ−¯νμντ,\nwhich suﬀers from three missing neutrinos but has a large signal yield and a well understood τ decay.",
    "The second is\nthe three-prong decay τ −→π−π+π−ντ(π0) which allows for a better kinematic reconstruction and higher purity\nat the expense of a smaller signal yield. For both modes, the most dangerous background is from Xb →Xc ¯Xc(X)\ndecays, where one of the Xc hadrons mimics a τ decay. Due to the similarity in the mass and lifetime, the kinematics\nof the Xc decay products can be ﬁendishly diﬃcult to disentangle from the signal.\n",
    "The signal yields are determined by three-dimensional ﬁts to variables that discriminate between signal and the\nvarious backgrounds. Examples include the q2 distribution or the τ −decay time. The latest LHCb measurements\n [51, 52] of R(D(∗)) are shown in Fig. 3 together with those of the B factories [53–58]. The fact that the hadron\ncollider measurements are competitive with those from the B-factories is a huge success story of the LHCb exper-\niment.",
    "The SM prediction is also depicted, which is 3.3 σ from the world average. Given the complexity of the\n2The B-factories also include the electronic modes.\n 123\n"
  ],
  "8": [
    "232\nEur. Phys. J. Spec. Top. (2024) 233:225–240\nmeasurements, caution should be taken when interpreting this discrepancy as a sign of NP, but it is interesting to\nnote that three seperate experiments consistency measure higher semitauonic yields than predicted and in more\nthan one τ decay channel. Further measurements, including those only accessible at the LHC like those using Λb\nbaryons [59] will be crucial to clarify the situation in the future.\n",
    "5 Searches for CP violation\nThe observed level of baryon asymmetry in the universe mandates sources of CP violation beyond the SM [60].\n The LHCb experiment is contributing to the search for new sources of CP violation in several diﬀerent ways. The\nﬁrst that we will discuss is the contribution from LHCb in testing the unitarity of the CKM matrix.",
    "Here, LHCb\ndominates the precision of the CKM angle γ, providing world-leading results on the CKM parameter sin(2β) and\nproviding important contributions to the CKM magnitude ratio |Vub|/|Vcb|.\n When LHCb started collecting data in 2009, the angle γ was the least precisely known of the CKM unitarity\ntriangle, with a precision of ∼25% [61]. Over a decade of LHCb measurements sensitive to the interference between\nb →c and b →u transitions have improved the precision by over a factor of six.",
    "Unlike the CKM parameter sin(2β),\nthere is no golden mode for γ measurements, which means that the ultimate precision is obtained by combining\nseveral diﬀerent B →Dh analyses. Therefore, the ability to reconstruct a wide variety of fully hadronic ﬁnal\nstates is a key experimental requirement for the experiment. Of particular importance is K −π separation as\nthe main sensitivity arises from CKM-suppressed decays B+ →¯\nD0K+, which would be swamped by the more\nabundant decay B+ →¯\n",
    "D0π+ if no particle ID requirements were applied. More recently, decay modes involving\nπ0 mesons were included [62] to further boost the sensitivity using charm decays such as D →h+h\n′−π0. The\nability to reconstruct neutral pions and obtain physics sensitivity from decays involving them is a surprise given\nthe large occupancy in the calorimeters. Other novel reconstruction techniques involve determining the signal yield\nof B →D∗0h decays without reconstructing the π0 from the D∗0 →D0π0 decay.",
    "This is possible due to the low\nQ-value of the D∗0 decay. All the diﬀerent B →Dh decays have a complementary sensitivity to γ and associated\nhadronic nuisance parameters. The combination of which results in γ = (65.4+3.8\n−4.2)◦, where the charm mixing\nparameters are also measured simultaneously [63]. Most of the measurements that contribute to this average use\nthe full LHCb dataset of 9 fb−1, although there are few which are yet to be updated such as that from Bs →DsK+\n [64].",
    "Being based on fully hadronic decays, the improved trigger system in run III will particularly beneﬁt these\nmeasurements in the future.\n The CKM parameter sin(2β) is another place where LHCb is currently world leading. Here, the golden mode is\nthe decay B0 →J/ψK0\ns, where the decay into a CP eigenstate allows for interference between the mixing and decay\namplitudes. There are two key experimental challenges associated with this analysis.",
    "The ﬁrst is the ability to\nreconstruct the long-lived K0\ns meson, which has an average decay length of around one metre in the LHCb detector.\n This is signiﬁcantly longer than for the B-factories due to the larger boost at the LHC centre of mass energy which\nresults in a comparatively lower reconstruction eﬃciency.",
    "This is one of the reasons why the precision on γ has\nbeen dominated by LHCb measurements for years whereas the world’s most precise measurement of sin(2β) has\nonly just become a measurement from LHCb.\n 2015\n2020\nPre-print date\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nTagging power [%]\nLeptonic\nHadronic\nFig. 4 Tagging power of hadronic and leptonic B decays reported in LHCb publications as a function of the pre-print date\n123\n"
  ],
  "9": [
    "Eur. Phys. J. Spec. Top. (2024) 233:225–240\n233\nThe other challenge for this measurement is ﬂavour tagging, as the ﬁnal state does not determine the ﬂavour\nof the B0 meson at production. Flavour tagging at a hadron collider is much more diﬃcult compared to the\nB-factories, where the two B mesons are quantum entangled and are produced in isolation. Flavour tagging at\nLHCb relies on two aspects of b¯b events in LHC collisions.",
    "The ﬁrst is to exploit correlations of accompanying\nparticles in the hadronisation of the b-hadron of interest, known as same-side tagging. The second is to exploit\nanticorrelations in the decay products of the other b-hadron produced in the event, known as opposite-side tagging.\n The performance of ﬂavour tagging is quantiﬁed by the tagging power, which represents the size of a perfectly\ntagged dataset that would have equal precision.",
    "The tagging power is a result of the exploitation of several diﬀerent\nweak correlations and has steadily improved as more sophisticated techniques have been employed to utilise more\ninclusive decay pathways. This can be seen in Fig. 4, which shows the tagging power reported in LHCb publications\nas a function of the preprint date. This improvement is one of the reasons why the latest precision of sin(2β) has\nimproved beyond the niave scaling of luminosity.\n",
    "Beyond the unitarity of the CKM matrix, CP violation in B0\ns mixing is also highly sensitive to many NP models\nwhich favour second and third generation couplings [65]. This means that the measurement of the CP violating\nphase in the B0\ns system, φs has unique NP potential. The golden modes for this observable is B0\ns →J/ψhh,\nwhere hh is either a pair of pions or kaons.",
    "In addition to ﬂavour tagging and particle ID, a key aspect of the\nLHCb performance is the time resolution needed due to the very fast oscillations of the B0\ns meson. This is where\nthe large boost provided in high energy LHC environment is highly advantageous, leading to a time resolution of\n35–45 fs. This performance is demonstrated by an ultra precise measurement of the B0\ns oscillation frequency [66]\nusing B0\ns →D−\ns π+ decays.",
    "The decay time of candidates that have undergone an oscillation or not is shown in\nFig. 5, showing that the remarkably fast oscillations can be resolved by the LHCb detector. This level of ﬁdelity\nis crucial for the measurement of φs, for which has recently been performed with the full LHCb run I–II dataset\nof 9 fb−1 [67]. The result is −0.039 ± 0.022 ± 0.006 rad which is consistent with the SM, and is two times more\nprecise than any other measurement.",
    "Despite the remarkable precision, the comparison to the SM is still limited\nby the statistical uncertainty of the measurement, meaning that there are excellent prospects for the upgraded\nLHCb detector in the future. Such progress will rely on control of the penguin pollution, which will be helped to\nbe controlled using the SU(3) related decay B0\ns →J/ψK∗0 [68].\n In order to observe CP violation directly in the decay of a particle, one needs two decay amplitudes with diﬀerent\nweak and strong phases.",
    "The size of the CP asymmetry is maximised when the magnitudes of the two amplitudes\nare of similar size. Fully hadronic charmless B decays are perfect laboratories for studying such large eﬀects, as\nboth tree- and loop-level diagrams contribute to the ﬁnal state. Furthermore, the CKM suppression of the tree-\nlevel b →u amplitude allows for a large CP asymmetry as it places the magnitude of that amplitude to a similar\nlevel of the loop diagram.",
    "The loop diagram typically occurs through a gluonic penguin, which ensures a strong\nphase diﬀerence with respect to the tree-level amplitude. Indeed, for three-body B+ →h+h−h+ decays, a 80%\nCP asymmetry was observed in certain kinematic regions [69].\n The complication with interpreting CP asymmetries in charmless B decays is that its size depends on the\namplitude magnitudes and the strong phase, which are diﬃcult to calculate.",
    "Fully hadronic decays cannot be\nfactorised in the same way that semileptonic decays can, which makes theoretical calculations much more chal-\nlenging. For this reason, cancelations between similar decays can be useful to bring uncertainties from QCD\nunder control. A well-known example of this is to compare the CP asymmetry of B0 →K+π−decays with its\nFig. 5 Decay time distribution of B0\ns →D−\ns π+ decays, split between cases in which the B0\ns has undergone oscillation or\nnot [66]\n123\n"
  ],
  "10": [
    "234\nEur. Phys. J. Spec. Top. (2024) 233:225–240\nisospin partner, B+ →K+π0. Given that only the spectator quark is diﬀerent between the two decays, one would\nexpect the CP asymmetry to be very similar if not the same. However, the CP asymmetries of the two decays,\nACP (B0 →K+π−) = −0.084 ± 0.004 and ACP (B+ →K+π0) = 0.040 ± 0.021, are over ﬁve standard deviations\nfrom each other, indicating either unexpectedly large hadronic eﬀects or even contributions from NP.",
    "This diﬀer-\nence is surprising and is known in the ﬁeld as the Kπ puzzle. Given the diﬃcult signature of the decay π0 →γγ,\nthe uncertainty is dominated by the B+ transition. As there is only one charged particle in the signature, there\nis no B vertex to reconstruct which is normally a vital signature to identify b-hadron decays. A measurement of\nthe B+ →K+π0 decay was therefore considered impossible at a hadron collider.",
    "However, due to the very large\nproduction at the LHC, a tight selection could be employed using the four-momentum of the π0 which allowed\nto reduce the background enough to determine the signal for a CP measurement [70]. The signal is not as clean\nas fully charged b-hadron decays, is still of remarkable purity given the challenging signature. The LHCb analysis\nallowed for the most precise measurement of the CP asymmetry in the world, which signiﬁcantly increased the\nKπ puzzle.",
    "The success of this measurement gives encouragement to other related decays such as B+ →pi+K0,\nwhich should be of a similar challenge and are crucial to understand the Kπ puzzle further via a sum-rule relation\n[71].\n Finally, all these searches described in this section so far have been using B meson decays. Despite the connection\nto baryeogenesis, no observation of CP violation has been made yet in baryons themselves. There was hope with\nevidence reported in Λ0\nb →pπ+π−π+ decays",
    "[72] but unfortunately faded when analysed with an increased dataset\n[73]. Searches are on-going in several diﬀerent decay modes of both Λb and Ξb baryons. Given the lack of baryon\noscillations in the SM, the main area of focus is charmless decays. Given the amplitudes involved it is inevitible\nthat CP violation will be eventually seen in baryons, which will mark another important milestone in the history\nof CP violation attained by LHCb after the observation of CP violation in charm decays [74].\n 6",
    "The case for a second LHCb upgrade\nThe second LHCb upgrade [46, 75] aims for an unprecedented luminosity of 1.5×1034 cm−2 s−1, which is expected\nto cause approximately 40 visible proton–proton interactions per crossing, yielding about 2000 charged particles\nwithin the LHCb’s area of coverage.",
    "To handle this substantial increase, changes are envisioned for the existing\nspectrometer components, including increasing their granularity, lowering the material within the detector, and\nincorporating advanced timing precision. This initiative will strive to preserve or enhance the current performance\nof the detector, particularly in areas such as track-ﬁnding eﬃciency and momentum resolution.\n",
    "The LHCb Upgrade II will fully harness the HL-LHC potential as a ﬂavour physics machine while maintaining\na rich and diverse research programme. A glimpse of the potential available at the LHC can be found in Fig. 6,\nwhich shows the vast increase of the number of b-hadrons that will be produced. Some of the measurements that\nLHCb Upgrade II will undertake will constrain theoretical models for decades to come.",
    "From the conclusion of\nthe HL-LHC to the commencement of the future circular collider (FCC), it will be crucial to have a robust set\nof measurements to guide future theoretical work. Neglecting to fully exploit the third family’s ﬂavour potential\ncould result in a missed opportunity.\n Although the LHCb Upgrade II presents great opportunities, it also poses substantial technological challenges.\n",
    "The key points of the upgrade for tracking, particle identiﬁcation, and data processing are summarised below.\n 9\n10\n10\n10\n11\n10\n12\n10\n13\n10\n14\n10\nProduced b-hadrons\n2000-2008\n2010-2018\n2022-2028\n2026-2035\nFig. 6 Number of b-hadrons produced or to be produced at the B-factories, run II of the LHC, the Belle II experiment\nand at the high luminosity LHC\n123\n"
  ],
  "11": [
    "Eur. Phys. J. Spec. Top. (2024) 233:225–240\n235\nThe VELO is a critical component of the LHCb upgrade physics agenda, designed to perform real-time track\nreconstruction from all LHC bunch crossings within the software trigger system. The enhanced luminosity projected\nfor Upgrade II necessitates a new and more capable VELO. This includes the ability to manage an enlarged data\noutput, higher radiation levels, and an increased occupancy.",
    "Innovative techniques are being devised to facilitate\nreal-time pattern recognition and correct association of each b-hadron to its originating primary vertex (PV). This\neﬀort will involve the development of a novel pixel detector with superior rate and timing capabilities, and a more\neﬃcient mechanical design.\n To better associate the decay products of heavy ﬂavor with their parent PV, eﬀective utilization of timing\ninformation is critical.",
    "Research indicates that through a timing precision of 50-100 ps, mis-association levels of\nPVs can be curtailed from about 20% to approximately 5%. Further, reducing the pixel pitch from its current\nsize of 55μm at Upgrade II is considered advantageous, especially for the VELO’s innermost region. Timing will\nnot only aid in the track reconstruction process but also help conserve computational resources.",
    "R &D for the\nVELO is currently ongoing with the major candidate solutions for the sensors including Planar Sensors, Low Gain\nAvalanche Diodes (LGADs) and 3D sensors.\n Upgrade II also plans changes to the downstream tracking system, which currently comprises a silicon strip\ndetector (UT) and three tracking stations (T-stations).",
    "The redesigned system will need to accommodate higher\noccupancies by enhancing detector granularity and minimizing incorrect matches between upstream and down-\nstream track segments.\n For the inner portions of the T-stations, as well as the UT, Monolithic Active Pixel Sensors (MAPS) are\nbeing considered. Optimization eﬀorts for the UT are ongoing, and both HV- and LV-CMOS solutions are under\nconsideration.",
    "Regarding the inner part of the T-stations, a preliminary prototype of the MightyPix silicon detector,\nbased on HV-CMOS technology, has been tested. Signiﬁcant synergies exist with R &D work conducted in the\ncontext of both the Mu3e experiment and the ATLAS Upgrade. The requisite number of detector layers is currently\nbeing investigated.",
    "As with the VELO, the integration of timing information into the tracking system could\nsubstantially improve the accuracy of matching upstream and downstream track segments.\n Quality particle identiﬁcation (PID) is a vital component in precision ﬂavor measurements. The PID subdetectors\nin the ongoing experiment will be improved and, in some cases, enhanced for the upcoming Upgrade II.",
    "The primary\nenhancements include improved granularity and for select subdetectors, rapid timing of a few tens of picoseconds.\n The improved timing helps to associate signals with a few proton–proton interactions in the bunch crossing.\n The RICH system for Upgrade II builds on the current detectors, consisting of an upstream RICH 1 for lower\nmomentum tracks, and a downstream RICH 2.",
    "To manage increased track multiplicity, it will be necessary to\nreplace the current MaPMTs with more granular photodetectors. Multiple technologies are under consideration,\nwith SiPMs being a prime candidate.\n An opportunity to enhance low-momentum hadron-identiﬁcation capabilities is under consideration by installing\na TORCH detector. This detector measures time-of-ﬂight by detecting internally reﬂected Cherenkov light pro-\nduced in a thin quartz plane.",
    "The TORCH can help identify kaons in the region below 10 GeV/c.\nThe electron, photon, and pi-zero identiﬁcation provided by the current electromagnetic calorimeter (ECAL)\nhas proved essential. A suitably designed new ECAL will be necessary for achieving high performance in key\nmodes and for ensuring a broad physics program at Upgrade II. One of the challenges for the ECAL at Upgrade\nII will be the harsh radiation environment.",
    "Solutions to these challenges include reducing the Moli`ere radius of\nthe converter, moving to a smaller cell size, and using fast timing information.\n Upgrade II aims to provide ECAL performance at least as good as the current detector in Run 1 and Run 2\nconditions. An active R &D program has begun to investigate potential technologies for the Upgrade II ECAL.\n",
    "It’s possible that the ﬁnal detector might use multiple solutions due to the rapid variation of multiplicity and\nradiation ﬂux with position.\n The current muon system in Upgrade I conditions would result in a degraded performance due to the higher\nbackground ﬂux foreseen for Upgrade II. Enhanced shielding will be necessary in front of the muon detector to\nmitigate the incidence of punch-through particles.",
    "This could involve substituting the HCAL with up to 1.7 ms\nof iron, thereby adding an extra four interaction lengths compared to the existing setup. As the HCAL’s main\nfunction of contributing to the hardware trigger will become obsolete starting from Run 3, this change is feasible.\n In terms of the muon system, upgrades are needed for the detectors in the most central areas of all stations, aiming\nfor a design with both superior granularity and rate capabilities.\n",
    "Potential solutions are the micro-resistive WELL detector (μ-RWELL) for the higher occupancy region, and\nMWPC or RPC detectors in the lower ﬂux region. R &D is ongoing to study all of these possibilities.\n The LHCb Upgrade II detector is expected to generate data in the range of 200 Tb per second. This vast\namount of data necessitates real-time processing and a substantial reduction before it can be stored.",
    "Advances\nin radiation-resistant optical links and commercial networking technology, along with the speciﬁc design of the\nLHCb that positions the readout cables outside of the detector acceptance, should enable the transmission of this\nmassive data volume to a computational farm by the time of Upgrade II.\n Data processing in Upgrade II presents a signiﬁcant challenge. Traditional trigger methods will not suﬃce for\nsubstantial data rate reduction at even the initial trigger stages.",
    "Instead, the data processing approach for Upgrade\n123\n"
  ],
  "12": [
    "236\nEur. Phys. J. Spec. Top. (2024) 233:225–240\nII will focus on pile-up suppression, prioritizing the early-stage discarding of detector hits not associated with\nthe speciﬁc proton–proton interaction of interest. Accurate timing data is vital for rapidly selecting reconstructed\nobjects based on their originating proton–proton interaction. Therefore, access to detailed timing information across\nmultiple subdetectors is imperative.",
    "It’s equally signiﬁcant to carry out an early-stage reconstruction of charged\nparticle trajectories and neutral particle clusters created within the LHCb acceptance, to optimally associate\nspeciﬁc heavy ﬂavour indicators with proton–proton interactions.",
    "LHCb has already showcased its proﬁciency in\nperforming a comprehensive oﬄine-quality detector alignment, calibration, and reconstruction in a near-real-time\nenvironment during Run 2, as well as its capacity to conduct precision physics assessments using this real-time\ndata processing.\n",
    "Adapting this capability to the more rigorous conditions of Upgrade II will require the construction of a processor\nfarm leveraging whichever technology or technologies are deemed most commercially sustainable over a decade\nfrom now.",
    "Given the increasing trend towards more diverse computing architectures, with CPU server farms\nbeing augmented with GPU or FPGA accelerators, it becomes crucial to sustain and expand collaborations with\ncomputing institutions that specialize in the design of these hybrid architectures. Research has been carried out\non FPGA-based downstream tracking.",
    "Collaborations with industry partners will be instrumental in ensuring\nthat LHCb’s trigger and reconstruction algorithms are optimally calibrated to make the best use of the most\ncost-eﬀective architecture.\n In conclusion, despite the technological challenges of the LHCb Upgrade II, it also oﬀers a unique opportunity to\ndevelop novel detector technologies during an exciting period of anticipation while we await the FCC.",
    "The combi-\nnation of achieving cutting-edge physics goals and advancing technological capabilities underscores the signiﬁcance\nof the LHCb Upgrade II.\n 7 Summary\nIn 2008, shortly before the LHCb experiment was due to start collecting data, the experiment published a roadmap\n [76] of six key measurements to be performed with high priority in the upcoming run. These were dominated by\ndecays with fully charged ﬁnal states, where the only leptons considered were muons.",
    "In this review we highlighted\nthree areas of b physics, but even within that highlight one can see a huge diversity of signatures, involving\nelectrons, τ-leptons, neutrinos and neutral pions. The last 15 years has brought about a huge expansion of the\nLHCb programme beyond what was considered possible at a hadron collider and is one of the great successes\nof the LHCb experiment.",
    "The next 15 years will certainly contain more surprises in addition to the expected\nimprovements to the measurements already established within the programme. The motivation for the LHCb\nupgrades is clear.\n This is not to mention the huge amount of physics potential for which we could not cover in this review. We\ndid not cover the pentaquark discovery [77] and associated measurements into exotic spectrospopy, which have a\nhuge interest both in and outside the ﬁeld.",
    "Beyond b-physics the LHCb physics programme includes a large and\ndiverse set of measurements, which have steadily expanded over the last decade. In ﬂavour physics, measurements\nof a wide variety of charm-quark measurements from oscillations to spectroscopy. In particular, one of LHCb’s\nlandmark measurements has been the discovery of CP violation in D →hh decays [74], which is a milestone in\nthe history of the ﬁeld.",
    "Beyond ﬂavour, there is a broad programme of electroweak physics measurements, from\ndrell-yan to top quark measurements. Highlights here include the W boson mass measurement [78] and ion-proton\ncross-section measurements [79], which inform background estimates in astrophysics.\n Given the unique opportunity of HL-HLC, pushing the LHCb experiment to its maximal capability is mandatory.\n",
    "There is a possibility that the current discrepancies in b →sμ+μ−and b →cτ −¯ντ could be resolved or new\nanomalies could emerge. In both cases, the LHCb Upgrade II will be a fundamental resource for future theoretical\nwork and, in turn, for upcoming experiments. It also provides an important bridge to design and implement new\ndetector technologies in the time period between the ﬁnal upgrades of ATLAS and CMS and the new generation\naccelerator complex, the FCC.",
    "It is clear to us that neither LHCb nor b-hadron physics will lose any relevance\nover the next decade, whether or not NP is discovered in that time.\n Funding\nOpen access funding provided by University of Zurich.\n Data availability No data associated in the manuscript.\n",
    "Open Access\nThis article is licensed under a Creative Commons Attribution 4.0 International License, which permits\nuse, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit\nto the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were\nmade.",
    "The images or other third party material in this article are included in the article’s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and\n123\n"
  ]
}